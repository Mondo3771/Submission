
\begin{document}
\title{COMS3008A Assignment 2 -- Report}
\author{Kabelo M Rankoane (2603828)}
\date{June 02 2024}
\maketitle
%\thispagestyle{empty}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\fancyhead[L]{COMS3008A Assignment}
%\vskip 3mm 
%\pagenumbering{roman}
%\newpage
\pagenumbering{arabic}
\section{Bitonic Sort}

\subsection*{Serial Pseudocode}
This is the pseudocode for the bitonic sort algorithm in serial:\\
\begin{figure}[ht]
    \begin{algorithm2e}
        \SetKwProg{Fn}{Function}{}{end}
        \Fn{bitonicMerge(a[], low, cnt, dir)}{
            \If{cnt > 1}{
                k $\leftarrow$ cnt / 2\;
                \For{i $\leftarrow$ low \KwTo low + k}{
                    \If{dir == (a[i] > a[i + k])}{
                        swap a[i] and a[i + k]\;
                    }
                }
                bitonicMerge(a, low, k, dir)\;
                bitonicMerge(a, low + k, k, dir)\;
            }
        }
        \Fn{bitonicSort(a[], low, cnt, dir)}{
            \If{cnt > 1}{
                k $\leftarrow$ cnt / 2\;
                bitonicSort(a, low, k, 1)\;
                bitonicSort(a, low + k, k, 0)\;
                bitonicMerge(a, low, cnt, dir)\;
            }
        }
    \end{algorithm2e}
    \caption{Bitonic Sort and Merge Algorithm in Serial}
    \label{fig:bitonic}
\end{figure}
This is the basic idea of the bitonic sort algorithm. The bitonicMerge function
is a recursive function that merges two arrays of size $n/2$ each. The
bitonicSort function is also a recursive function that first sorts the first
half of the array in ascending order and the second half in descending order.
The bitonicMerge function is then called to merge the two halves.
This is the serial implementation and the base of what i will be using to
implement the parallel version of the bitonic sort algorithm.

\section{Baseline Algorithm}
I used Quicksort as the baseline algorithm for this assignment. Quicksort is a
comparison sort and is a divide-and-conquer algorithm. It works by selecting a
'pivot' element from the array and partitioning the other elements into two
sub-arrays according to whether they are less than or greater than the pivot. I
picked the last elements in the array as the pivot element. The pivot element
is then placed in its correct position in the array and the array is
partitioned into two sub-arrays. The quicksort function is then called
recursively on the two sub-arrays.
This is what i compare the time for my OPENMP and MPI implementations of the
bitonic sort algorithm to.

\section{Parallel Implementation}

\subsection{OPENMP Implementation}
Using the Bitonic Sort Serial as a base, I used the task construct to create
task that could be run in parallel. Two task are created in the bitonicSort and
theres a taskwait so that the task are completed before the bitonicMerge is
called. Then the bitonicMerge is called which then create 2 task that call
bitonicMerge on the two halves of the array. This is done recursively until the
array is sorted.But through testing i found that the parallel implementation
had been slow so i added a cutoff point where the serial implementation would
be used instead of the parallel implementation. This cutoff point was set to
1000. This allowed me to reduce the overhead of creating tasks for small
arrays.

These are tehe Results of the OPENMP implementation on different number of
threads on an array of size  $2^{24}$:
\begin{table}[ht]
    \centering
    \setlength{\tabcolsep}{10pt} % Add padding
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Threads} & \textbf{Speedup} & \textbf{Time Taken} \\
        \hline
        1                & 0.2570223        & 14.018849           \\
        2                & 0.316548         & 11.382653           \\
        4                & 0.496615         & 7.219549            \\
        8                & 0.669296         & 5.419865            \\
        16               & 0.775642         & 4.649495            \\
        32               & 0.781515         & 4.599116            \\
        \hline
    \end{tabular}
    \caption{Threads, Speedup and Time Taken}
    \label{table:1}
\end{table}\\
As we can see from the table, the speedup increases as the number of threads
increase but it platuas at 32 threads. This is because the number of threads is
greater than the number of cores on the machine i was testing on. This causes
the overhead of
creating threads to be greater than the speedup gained from the parallel
implementation. This is why the speedup is the relativly the same for 16
threads and 32 threads.
Therefore if i had to run the program on a machine with more cores would have
achieved a higher speedup for 32 threads.

\subsection{MPI Implementation}
The MPI implementation of the bitonic sort algorithm is a bit more complex than
the OpenMP implementation. Initially, the program runs the baseline algorithm
on process 0 for benchmarking. We then run the Bitonic Sort MPI, distributing
the array among the processes. Each process runs the bitonic sort on its piece
of the array. Depending on the rank and number of processors, I assign the
direction accordingly. After this, I will have n/2(n is the number of
processors) bitonic sequences that need
to be sorted. I then let process 0 handle the merging of these sequences by
calling my recursive bitonicMerge function.

\begin{table}[ht]
    \centering
    \setlength{\tabcolsep}{10pt} % Add padding
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Number of Processes} & \textbf{Speedup MPI} & \textbf{Time
            Taken MPI}
        \\
        \hline
        1                            & 0.191474             & 15.646154
        \\
        2                            & 0.302780             & 10.351526
        \\
        4                            & 0.417547             & 8.764265
        \\
        \hline
    \end{tabular}
    \caption{Number of Processes, Speedup MPI, and Time Taken MPI}
    \label{table:2}
\end{table}
\section{Correctness and Performance Analysis}
For Correctness I just checked if the array was sorted in ascending order using the IsSorted function i made.
Below is a Table of the time taken for the baseline algorithm, Bitonic Sort in Serial and the parallel implementations: Note that the baseline is run in each of the parallel implementations to get a fair comparison.Therefore Quicksort sorts the same array as the parallel implementation and that i will be runnig OpenMP with 16 threads and MPI with 4 processes.
\begin{table}[h]
    \centering
    \small
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \textbf{Size ($2^n$)} & \textbf{Bitonic Serial Time} & \textbf{QuickSort Time} & \textbf{Bitonic OpenMP Time} & \textbf{OpenMP Speedup} & \textbf{Bitonic MPI Time} & \textbf{MPI Speedup} \\
        \hline
        10 & 0.001626 & 0.000601 & 0.003077 & 0.195289 & 0.004364 & 0.123490 \\
        12 & 0.006519 & 0.002495 & 0.004260 & 0.585759 & 0.005999 & 0.452334 \\
        14 & 0.027727 & 0.006634 & 0.007855 & 0.844590 & 0.028486 & 0.426637 \\
        16 & 0.051274 & 0.015201 & 0.018460 & 0.823429 & 0.107221 & 0.405564 \\
        18 & 0.158934 & 0.057405 & 0.063904 & 0.898293 & 0.112836 & 0.335153 \\
        20 & 0.666243 & 0.204221 & 0.216014 & 0.945408 & 0.385627 & 0.679878 \\
        22 & 3.025937 & 0.837932 & 1.013498 & 0.826772 & 1.724959 & 0.433854 \\
        24 & 13.860130 & 3.595785 & 4.674581 & 0.769221 & 7.939528 & 0.408979 \\
        26 & 63.051318 & 15.609176 & 21.517336 & 0.725423 & 35.775854 & 0.389256 \\
        \hline
    \end{tabular}
    \caption{Time Taken and Speedup for Different Sort Algorithms}
    \label{table:sort_results}
\end{table}


\section{Conclusion}
Despite implementing the parallel versions of the bitonic sort algorithm, they still perform slower on my machine. This is likely due to the limited number of processors available. However, it's important to note that the bitonic sort algorithm has a time complexity of $O( n log^2( n))$, which is less superior to quicksort's average time complexity of $O(n log n)$. Therefore, I believe that with more processors, the speedup of the parallel bitonic sort would be significant. Because the the Time Complexity would be $O(n/p * log^2 (n))$
where p is the number of processors or threads. Even thou this would increase the overhead of creating threads or processes, the speedup would be greater than the overhead. Therefore, the parallel bitonic sort algorithm is a viable alternative to quicksort for large arrays with a large number of processors.  
\end{document}
